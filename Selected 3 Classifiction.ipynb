{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Phase one Update </h2> \n",
    "<h3>Converting Clustering to Classification</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " **importing libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.svm import LinearSVC , SVC\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Read dataset\n",
    "dataset=pd.read_json(\"finalCleanedData.csv\")\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert list to string in BookSummary\n",
    "dataset[\"BookSummary\"]=dataset[\"BookSummary\"].apply(lambda row: ' '.join(row))\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert list to string in Author and Class columns\n",
    "dataset[\"Author\"]=dataset[\"Author\"].apply(lambda row: '-'.join(row))\n",
    "dataset[\"Class\"]=dataset[\"Class\"].apply(lambda row: '-'.join(row))\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"the number od unique on Author column : \",len(dataset[\"Author\"].unique()))\n",
    "print (\"the number od unique on Class column : \",len(dataset[\"Class\"].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#takeing Important columns \n",
    "Dataset = dataset[[\"BookTitle\",\"BookSummary\",\"Author\",\"Class\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Label Encoding (Author - class)</h3> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#label Encoding on Author for first classification \n",
    "Dataset.insert(3,\"Author_encode\", LabelEncoder().fit_transform(Dataset[\"Author\"].values), True)\n",
    "#label Encoding on class for first classification \n",
    "Dataset.insert(5,\"Class_encode\", LabelEncoder().fit_transform(Dataset[\"Class\"].values), True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Vectorize Text by Term frequency–Inverse document frequency</h3> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vectorize Text by Term frequency–Inverse document frequency\n",
    "tfidf_vect = TfidfVectorizer(smooth_idf=False)\n",
    "tfidf = tfidf_vect.fit_transform(Dataset['BookSummary'].values)\n",
    "tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tfidf_vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>convert data to np array</h3> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert data to np array\n",
    "X = tfidf.toarray()\n",
    "y_Authors = np.array(Dataset[\"Author_encode\"])\n",
    "y_Classes = np.array(Dataset[\"Class_encode\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_Authors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Classification based on Authors as a label </h2> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Split data into training and testing </h3> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y_Authors, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>build and fit LinearSVC model </h3> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model =LinearSVC()\n",
    "history=model.fit(X_train,y_train)\n",
    "print(\"training data accu : \",round(model.score(X_train,y_train)*100,2),\"%\")\n",
    "print(\"Testing data accu: \",round(model.score(X_test,y_test)*100,2),\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Predict and calculate mean square error</h3> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_y_hat=model.predict(X_train)\n",
    "testing_y_hat=model.predict(X_test)\n",
    "print(\"MSE on training data: \",mean_squared_error(y_train,training_y_hat))\n",
    "print(\"MSE on testing data: \",mean_squared_error(y_test,testing_y_hat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>visualize some of predicted data</h3> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot train vs test accuracy per epoch\n",
    "plt.figure(figsize=(20, 10))\n",
    "# Use the history metrics\n",
    "plt.plot(testing_y_hat[:150])\n",
    "plt.plot(y_test[:150])\n",
    "\n",
    "# Make it pretty\n",
    "plt.title('compare between y_hat and real y')\n",
    "plt.ylabel('labels')\n",
    "plt.xlabel('summery')\n",
    "plt.legend(['Train', 'Test'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Classification based on classes as a label </h2> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Split data into training and testing </h3> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X, y_Classes, test_size=0.45, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>build and fit LinearSVC model </h3> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 =LinearSVC()\n",
    "history2=model2.fit(X_train2,y_train2)\n",
    "print(\"training data accu : \",round(model2.score(X_train2,y_train2)*100,2),\"%\")\n",
    "print(\"Testing data accu: \",round(model2.score(X_test2,y_test2)*100,2),\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Predict and calculate mean square error</h3> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_y_hat2=model2.predict(X_train2)\n",
    "testing_y_hat2=model2.predict(X_test2)\n",
    "print(\"MSE on training data: \",mean_squared_error(y_train2,training_y_hat2))\n",
    "print(\"MSE on testing data: \",mean_squared_error(y_test2,testing_y_hat2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>visualize some of predicted data</h3> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot train vs test accuracy per epoch\n",
    "plt.figure(figsize=(20, 10))\n",
    "# Use the history metrics\n",
    "plt.plot(testing_y_hat2[:150])\n",
    "plt.plot(y_test2[:150])\n",
    "\n",
    "# Make it pretty\n",
    "plt.title('compare between y_hat and real y')\n",
    "plt.ylabel('labels')\n",
    "plt.xlabel('books')\n",
    "plt.legend(['Train', 'Test'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
